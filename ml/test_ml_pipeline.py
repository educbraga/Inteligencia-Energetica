"""
PIPELINE ML ENERGIA SOLAR - TESTE PRINCIPAL
===========================================

Este √© o arquivo principal para testar o pipeline de Machine Learning
para previs√£o de energia solar fotovoltaica em Goi√°s.

FUNCIONALIDADES:
- Conex√£o Snowflake + AWS
- Extra√ß√£o e an√°lise de dados
- Treinamento de modelos ML
- Previs√µes para 30 dias
- Exporta√ß√£o para CSV
- Relat√≥rios de performance

MODO DE USO:
python test_ml_pipeline.py

ARQUIVOS GERADOS:
- previsoes_energia_solar_30_dias.csv
- performance_modelos.csv  
- resumo_previsoes_por_usina.csv
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from solar_ml_pipeline import SolarEnergyMLPipeline
import warnings
warnings.filterwarnings('ignore')

class SolarMLTester:
    """
    Classe principal para testar o pipeline de ML
    """
    
    def __init__(self):
        self.pipeline = SolarEnergyMLPipeline()
        self.results = {}
        
    def run_connectivity_test(self):
        """Teste 1: Conectividade"""
        print("üîó Teste 1: Verificando conectividade...")
        
        snowflake_ok = self.pipeline.connect_snowflake()
        aws_ok = self.pipeline.connect_aws()
        
        if snowflake_ok and aws_ok:
            print("   ‚úÖ Todas as conex√µes OK")
            return True
        else:
            print("   ‚ùå Falha nas conex√µes")
            return False
    
    def run_data_analysis(self):
        """Teste 2: An√°lise de dados"""
        print("\nüìä Teste 2: An√°lise explorat√≥ria...")
        
        try:
            # Query b√°sica de estat√≠sticas
            stats_query = """
            SELECT 
                COUNT(*) as total_registros,
                COUNT(DISTINCT id_ons) as total_usinas,
                MIN(instante) as data_inicio,
                MAX(instante) as data_fim,
                AVG(val_geracao_mw) as geracao_media,
                MAX(val_geracao_mw) as geracao_maxima,
                MIN(val_geracao_mw) as geracao_minima
            FROM IE_DB.STAGING.stg_usina_geracao
            WHERE nom_tipocombustivel = 'Fotovoltaica' AND ID_ESTADO = 'GO'
            """
            
            stats_df = pd.read_sql(stats_query, self.pipeline.snowflake_conn)
            
            print("   üìà Estat√≠sticas gerais:")
            for col in stats_df.columns:
                value = stats_df[col].iloc[0]
                print(f"      {col}: {value}")
            
            self.results['stats'] = stats_df
            return True
            
        except Exception as e:
            print(f"   ‚ùå Erro na an√°lise: {e}")
            return False
    
    def run_ml_training(self):
        """Teste 3: Treinamento ML"""
        print("\nüéØ Teste 3: Treinamento de modelos...")
        
        try:
            # Extrair dados para treinamento (2023 at√© atual - ~3 anos)
            current_date = datetime.now().strftime('%Y-%m-%d')
            df = self.pipeline.extract_data('2023-01-01', current_date)
            
            if df.empty:
                print("   ‚ùå Nenhum dado extra√≠do")
                return False
            
            # Normalizar colunas
            if 'ID_USINA' in df.columns:
                df['id_usina'] = df['ID_USINA']
            if 'GERACAO_MWH' in df.columns:
                df['geracao_mwh'] = df['GERACAO_MWH']
            if 'MEDICAO_DATA_HORA' in df.columns:
                df['medicao_data_hora'] = df['MEDICAO_DATA_HORA']
            
            df['medicao_data_hora'] = pd.to_datetime(df['medicao_data_hora'])
            
            print(f"   üìä Dados: {len(df)} registros, {df['id_usina'].nunique()} usinas")
            
            # ====== ENGENHARIA DE FEATURES AVAN√áADA ======
            print("   üîß Aplicando Engenharia de Features Avan√ßada...")
            
            # 1. FEATURES TEMPORAIS B√ÅSICAS
            df['hora'] = df['medicao_data_hora'].dt.hour
            df['dia_semana'] = df['medicao_data_hora'].dt.dayofweek  # 0=Monday, 6=Sunday
            df['mes'] = df['medicao_data_hora'].dt.month
            df['dia_ano'] = df['medicao_data_hora'].dt.dayofyear
            df['semana_ano'] = df['medicao_data_hora'].dt.isocalendar().week
            df['trimestre'] = df['medicao_data_hora'].dt.quarter
            
            # 2. FEATURES C√çCLICAS (Sine/Cosine) - CR√çTICO para padr√µes temporais
            # Hora do dia (0-23) -> ciclo 24h
            df['hora_sin'] = np.sin(2 * np.pi * df['hora'] / 24)
            df['hora_cos'] = np.cos(2 * np.pi * df['hora'] / 24)
            
            # Dia da semana (0-6) -> ciclo semanal
            df['dia_semana_sin'] = np.sin(2 * np.pi * df['dia_semana'] / 7)
            df['dia_semana_cos'] = np.cos(2 * np.pi * df['dia_semana'] / 7)
            
            # M√™s (1-12) -> ciclo anual
            df['mes_sin'] = np.sin(2 * np.pi * df['mes'] / 12)
            df['mes_cos'] = np.cos(2 * np.pi * df['mes'] / 12)
            
            # Dia do ano (1-365) -> ciclo anual
            df['dia_ano_sin'] = np.sin(2 * np.pi * df['dia_ano'] / 365)
            df['dia_ano_cos'] = np.cos(2 * np.pi * df['dia_ano'] / 365)
            
            # 3. FEATURES SOLARES BASEADAS EM POSI√á√ÉO ASTRON√îMICA
            # Aproxima√ß√£o do nascer/p√¥r do sol para Goi√°s (latitude ~-16¬∞)
            def solar_elevation_angle(hour, day_of_year, latitude=-16.0):
                """Calcula √¢ngulo de eleva√ß√£o solar aproximado"""
                # Declina√ß√£o solar
                declination = 23.45 * np.sin(np.radians(360 * (284 + day_of_year) / 365))
                # √Çngulo hor√°rio
                hour_angle = 15 * (hour - 12)  # 15¬∞ por hora
                # √Çngulo de eleva√ß√£o
                elevation = np.arcsin(
                    np.sin(np.radians(latitude)) * np.sin(np.radians(declination)) +
                    np.cos(np.radians(latitude)) * np.cos(np.radians(declination)) * np.cos(np.radians(hour_angle))
                )
                return np.degrees(elevation)
            
            df['elevacao_solar'] = solar_elevation_angle(df['hora'], df['dia_ano'])
            df['sol_visivel'] = (df['elevacao_solar'] > 0).astype(int)  # 1 se sol est√° vis√≠vel
            df['intensidade_solar'] = np.maximum(0, df['elevacao_solar'] / 90)  # Normalizado 0-1
            
            # 4. FEATURES CATEG√ìRICAS AVAN√áADAS
            # Per√≠odo do dia mais espec√≠fico
            def get_periodo_detalhado(hora):
                if 0 <= hora <= 5:
                    return 0  # Madrugada
                elif 6 <= hora <= 8:
                    return 1  # Manh√£ inicial
                elif 9 <= hora <= 11:
                    return 2  # Manh√£
                elif 12 <= hora <= 14:
                    return 3  # Meio-dia
                elif 15 <= hora <= 17:
                    return 4  # Tarde
                elif 18 <= hora <= 20:
                    return 5  # Final tarde
                else:
                    return 6  # Noite
            
            df['periodo_detalhado'] = df['hora'].apply(get_periodo_detalhado)
            
            # Esta√ß√£o do ano
            def get_estacao(mes):
                if mes in [12, 1, 2]:
                    return 0  # Ver√£o
                elif mes in [3, 4, 5]:
                    return 1  # Outono
                elif mes in [6, 7, 8]:
                    return 2  # Inverno
                else:
                    return 3  # Primavera
            
            df['estacao'] = df['mes'].apply(get_estacao)
            
            # Fim de semana vs dia √∫til
            df['fim_semana'] = (df['dia_semana'].isin([5, 6])).astype(int)  # S√°b/Dom
            
            # 5. FEATURES DE LAG (valores anteriores) - POR USINA
            print("      üìà Criando features de lag...")
            df = df.sort_values(['id_usina', 'medicao_data_hora'])
            
            # Lags de 1h, 2h, 3h, 6h, 12h, 24h, 48h, 168h (1 semana)
            lag_periods = [1, 2, 3, 6, 12, 24, 48, 168]
            for lag in lag_periods:
                df[f'geracao_lag_{lag}h'] = df.groupby('id_usina')['geracao_mwh'].shift(lag)
            
            # 6. FEATURES DE M√âDIAS M√ìVEIS - POR USINA
            print("      üìä Criando m√©dias m√≥veis...")
            windows = [3, 6, 12, 24, 48, 168]  # 3h, 6h, 12h, 1d, 2d, 1sem
            for window in windows:
                df[f'geracao_ma_{window}h'] = df.groupby('id_usina')['geracao_mwh'].rolling(
                    window=window, min_periods=1
                ).mean().reset_index(0, drop=True)
            
            # 7. FEATURES ESTAT√çSTICAS AVAN√áADAS
            print("      üìè Criando features estat√≠sticas...")
            # M√©dias m√≥veis com diferentes janelas
            for window in [6, 24, 168]:
                # Desvio padr√£o m√≥vel
                df[f'geracao_std_{window}h'] = df.groupby('id_usina')['geracao_mwh'].rolling(
                    window=window, min_periods=1
                ).std().reset_index(0, drop=True)
                
                # Diferen√ßa da m√©dia m√≥vel
                df[f'diff_ma_{window}h'] = df['geracao_mwh'] - df[f'geracao_ma_{window}h']
                
                # Percentual da m√©dia m√≥vel
                df[f'pct_ma_{window}h'] = df['geracao_mwh'] / (df[f'geracao_ma_{window}h'] + 1e-8)
            
            # 8. FEATURES DE VARIA√á√ÉO TEMPORAL
            # Diferen√ßas entre per√≠odos
            df['diff_1h'] = df.groupby('id_usina')['geracao_mwh'].diff(1)
            df['diff_24h'] = df.groupby('id_usina')['geracao_mwh'].diff(24)
            df['diff_168h'] = df.groupby('id_usina')['geracao_mwh'].diff(168)
            
            # Taxa de mudan√ßa
            df['rate_change_1h'] = df['diff_1h'] / (df['geracao_lag_1h'] + 1e-8)
            df['rate_change_24h'] = df['diff_24h'] / (df['geracao_lag_24h'] + 1e-8)
            
            # 9. FEATURES DE INTERA√á√ÉO
            # Hora x Esta√ß√£o (intera√ß√£o importante para energia solar)
            df['hora_x_estacao'] = df['hora'] * df['estacao']
            df['elevacao_x_estacao'] = df['elevacao_solar'] * df['estacao']
            
            # 10. FEATURES ESPEC√çFICAS POR USINA
            # Encoding da usina (pode capturar diferen√ßas de capacidade/localiza√ß√£o)
            usina_mapping = {usina: idx for idx, usina in enumerate(df['id_usina'].unique())}
            df['usina_encoded'] = df['id_usina'].map(usina_mapping)
            
            # Capacidade relativa (baseada na m√©dia hist√≥rica de cada usina)
            usina_capacity = df.groupby('id_usina')['geracao_mwh'].mean()
            df['capacidade_relativa'] = df['id_usina'].map(usina_capacity)
            df['geracao_normalizada'] = df['geracao_mwh'] / df['capacidade_relativa']
            
            # Remover linhas com NaN (devido aos lags)
            print("      üßπ Removendo dados com NaN...")
            df_clean = df.dropna()
            print(f"      üìä Dados ap√≥s limpeza: {len(df_clean)} registros (removidos {len(df) - len(df_clean)})")
            
            # Selecionar features finais (excluir colunas n√£o num√©ricas e target)
            exclude_cols = [
                'geracao_mwh', 'id_usina', 'medicao_data_hora', 
                'ID_USINA', 'MEDICAO_DATA_HORA', 'GERACAO_MWH'  # Vers√µes mai√∫sculas
            ]
            
            all_cols = df_clean.columns.tolist()
            feature_cols = [col for col in all_cols if col not in exclude_cols]
            
            # Verificar se todas as features s√£o num√©ricas
            numeric_features = []
            for col in feature_cols:
                if df_clean[col].dtype in ['int64', 'float64', 'int32', 'float32']:
                    numeric_features.append(col)
            
            print(f"   ‚úÖ Features Engineering Completa!")
            print(f"      üìä Total de features: {len(numeric_features)}")
            print(f"      üîß Categorias de features:")
            print(f"         ‚Ä¢ Temporais b√°sicas: 6")
            print(f"         ‚Ä¢ C√≠clicas (sin/cos): 8") 
            print(f"         ‚Ä¢ Solares (astron√¥micas): 3")
            print(f"         ‚Ä¢ Categ√≥ricas: 4")
            print(f"         ‚Ä¢ Lags: {len(lag_periods)}")
            print(f"         ‚Ä¢ M√©dias m√≥veis: {len(windows)}")
            print(f"         ‚Ä¢ Estat√≠sticas: ~18")
            print(f"         ‚Ä¢ Varia√ß√µes temporais: 5")
            print(f"         ‚Ä¢ Intera√ß√µes: 2")
            print(f"         ‚Ä¢ Espec√≠ficas por usina: 3")
            
            # Preparar dados ML
            feature_cols = numeric_features
            df = df_clean  # Usar dados limpos
            X = df[feature_cols].values
            y = df['geracao_mwh'].values
            
            # Configurar TimeSeriesSplit para s√©ries temporais
            tscv = TimeSeriesSplit(n_splits=5)
            
            print(f"   üîÑ Usando TimeSeriesSplit com 5 folds temporais...")
            
            # Treinar modelo com valida√ß√£o temporal
            model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
            
            # Valida√ß√£o cruzada temporal
            cv_scores_r2 = []
            cv_scores_mae = []
            cv_scores_rmse = []
            
            fold_num = 1
            for train_idx, test_idx in tscv.split(X):
                X_train_fold, X_test_fold = X[train_idx], X[test_idx]
                y_train_fold, y_test_fold = y[train_idx], y[test_idx]
                
                # Treinar no fold
                model.fit(X_train_fold, y_train_fold)
                y_pred_fold = model.predict(X_test_fold)
                
                # M√©tricas do fold
                r2_fold = r2_score(y_test_fold, y_pred_fold)
                mae_fold = mean_absolute_error(y_test_fold, y_pred_fold)
                rmse_fold = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))
                
                cv_scores_r2.append(r2_fold)
                cv_scores_mae.append(mae_fold)
                cv_scores_rmse.append(rmse_fold)
                
                print(f"      Fold {fold_num}: R¬≤={r2_fold:.4f}, MAE={mae_fold:.2f}, RMSE={rmse_fold:.2f}")
                fold_num += 1
            
            # Treinar modelo final com todos os dados
            final_split_idx = int(len(X) * 0.8)  # 80% para treino final
            X_train_final, X_test_final = X[:final_split_idx], X[final_split_idx:]
            y_train_final, y_test_final = y[:final_split_idx], y[final_split_idx:]
            
            model.fit(X_train_final, y_train_final)
            y_pred_final = model.predict(X_test_final)
            
            # M√©tricas finais
            r2_final = r2_score(y_test_final, y_pred_final)
            mae_final = mean_absolute_error(y_test_final, y_pred_final)
            rmse_final = np.sqrt(mean_squared_error(y_test_final, y_pred_final))
            
            print(f"   \n   ‚úÖ Modelo Random Forest - Resultados:")
            print(f"      üìä Cross-Validation (5 folds):")
            print(f"         R¬≤ m√©dio: {np.mean(cv_scores_r2):.4f} (¬±{np.std(cv_scores_r2):.4f})")
            print(f"         MAE m√©dio: {np.mean(cv_scores_mae):.2f} (¬±{np.std(cv_scores_mae):.2f}) MWh")
            print(f"         RMSE m√©dio: {np.mean(cv_scores_rmse):.2f} (¬±{np.std(cv_scores_rmse):.2f}) MWh")
            print(f"      üìà Teste Final (Hold-out):")
            print(f"         R¬≤ final: {r2_final:.4f}")
            print(f"         MAE final: {mae_final:.2f} MWh")
            print(f"         RMSE final: {rmse_final:.2f} MWh")
            
            # AN√ÅLISE DE IMPORT√ÇNCIA DAS FEATURES
            print(f"\n   üéØ Analisando import√¢ncia das features...")
            feature_importance = pd.DataFrame({
                'feature': feature_cols,
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print(f"      üèÜ Top 10 features mais importantes:")
            for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):
                print(f"         {i+1:2d}. {row['feature']:<25} {row['importance']:.4f}")
            
            # Salvar performance
            performance_data = {
                'modelo': ['RandomForest_AdvancedFeatures'],
                'metodo_validacao': ['TimeSeriesSplit_5_folds'],
                'r2_cv_mean': [np.mean(cv_scores_r2)],
                'r2_cv_std': [np.std(cv_scores_r2)],
                'mae_cv_mean': [np.mean(cv_scores_mae)],
                'mae_cv_std': [np.std(cv_scores_mae)],
                'rmse_cv_mean': [np.mean(cv_scores_rmse)],
                'rmse_cv_std': [np.std(cv_scores_rmse)],
                'r2_final': [r2_final],
                'mae_final': [mae_final],
                'rmse_final': [rmse_final],
                'features_total': [len(feature_cols)],
                'features_top10': [', '.join(feature_importance.head(10)['feature'].tolist())],
                'dados_totais': [len(X)],
                'dados_treino_final': [len(X_train_final)],
                'dados_teste_final': [len(X_test_final)],
                'periodo_inicio': ['2022-01-01'],
                'periodo_fim': [current_date],
                'data_teste': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')]
            }
            
            # Salvar tamb√©m import√¢ncia das features
            self.results['feature_importance'] = feature_importance
            
            self.results['performance'] = pd.DataFrame(performance_data)
            self.results['model'] = model
            self.results['training_data'] = df
            
            return True
            
        except Exception as e:
            print(f"   ‚ùå Erro no treinamento: {e}")
            return False
    
    def create_predictions(self, days=30):
        """Teste 4: Criar previs√µes"""
        print(f"\nüîÆ Teste 4: Criando previs√µes ({days} dias)...")
        
        try:
            df = self.results['training_data']
            
            # √öltima data dos dados
            last_date = df['medicao_data_hora'].max()
            
            # Datas futuras
            future_dates = pd.date_range(
                start=last_date + timedelta(hours=1),
                periods=days * 24,
                freq='H'
            )
            
            predictions = []
            
            for usina in df['id_usina'].unique():
                print(f"   üìä Processando {usina}...")
                usina_data = df[df['id_usina'] == usina].copy()
                
                # Padr√µes por hora
                hourly_pattern = usina_data.groupby('hora')['geracao_mwh'].agg(['mean', 'std']).fillna(0)
                
                for future_date in future_dates:
                    hora = future_date.hour
                    
                    # Previs√£o baseada no padr√£o hist√≥rico
                    base_generation = hourly_pattern.loc[hora, 'mean'] if hora in hourly_pattern.index else 0
                    
                    # Adicionar variabilidade
                    if hourly_pattern.loc[hora, 'std'] > 0:
                        noise = np.random.normal(0, hourly_pattern.loc[hora, 'std'] * 0.05)
                        prediction = base_generation + noise
                    else:
                        prediction = base_generation
                    
                    # N√£o pode ser negativo
                    prediction = max(0, prediction)
                    
                    predictions.append({
                        'id_usina': usina,
                        'medicao_data_hora': future_date,
                        'geracao_mwh': prediction,
                        'modelo': 'pattern_based',
                        'hora': hora
                    })
            
            predictions_df = pd.DataFrame(predictions)
            
            print(f"   ‚úÖ Previs√µes geradas:")
            print(f"      Total: {len(predictions_df)} registros")
            print(f"      Usinas: {predictions_df['id_usina'].nunique()}")
            print(f"      Per√≠odo: {predictions_df['medicao_data_hora'].min()} at√© {predictions_df['medicao_data_hora'].max()}")
            
            self.results['predictions'] = predictions_df
            return True
            
        except Exception as e:
            print(f"   ‚ùå Erro nas previs√µes: {e}")
            return False
    
    def save_results(self):
        """Teste 5: Salvar resultados"""
        print("\nüíæ Teste 5: Salvando resultados...")
        
        try:
            base_path = '/home/decode/workspace/Inteligencia-Energetica/ml'
            
            # 1. Previs√µes
            if 'predictions' in self.results:
                pred_file = f"{base_path}/previsoes_energia_solar_30_dias.csv"
                self.results['predictions'].to_csv(pred_file, index=False)
                print(f"   ‚úÖ Previs√µes: {pred_file}")
            
            # 2. Performance
            if 'performance' in self.results:
                perf_file = f"{base_path}/performance_modelos.csv"
                self.results['performance'].to_csv(perf_file, index=False)
                print(f"   ‚úÖ Performance: {perf_file}")
            
            # 3. Resumo por usina
            if 'predictions' in self.results:
                resumo = self.results['predictions'].groupby('id_usina')['geracao_mwh'].agg([
                    'count', 'mean', 'max', 'sum'
                ]).round(2)
                resumo.columns = ['Total_Horas', 'Media_MWh', 'Maximo_MWh', 'Total_MWh']
                
                resumo_file = f"{base_path}/resumo_previsoes_por_usina.csv"
                resumo.to_csv(resumo_file)
                print(f"   ‚úÖ Resumo: {resumo_file}")
                
                print(f"\n   üìã Resumo por usina (30 dias):")
                print(resumo)
            
            # 4. Import√¢ncia das Features
            if 'feature_importance' in self.results:
                feat_file = f"{base_path}/importancia_features.csv"
                self.results['feature_importance'].to_csv(feat_file, index=False)
                print(f"   ‚úÖ Import√¢ncia Features: {feat_file}")
            
            return True
            
        except Exception as e:
            print(f"   ‚ùå Erro ao salvar: {e}")
            return False
    
    def run_complete_test(self):
        """Executa todos os testes em sequ√™ncia"""
        print("=" * 70)
        print("üåû PIPELINE ML ENERGIA SOLAR - TESTE COMPLETO")
        print("=" * 70)
        
        tests = [
            ("Conectividade", self.run_connectivity_test),
            ("An√°lise de Dados", self.run_data_analysis),
            ("Treinamento ML", self.run_ml_training),
            ("Previs√µes", lambda: self.create_predictions(30)),
            ("Salvamento", self.save_results)
        ]
        
        success_count = 0
        
        for test_name, test_func in tests:
            try:
                if test_func():
                    success_count += 1
                else:
                    print(f"\n‚ùå Falha no teste: {test_name}")
                    break
            except Exception as e:
                print(f"\n‚ùå Erro no teste {test_name}: {e}")
                break
        
        # Resultado final
        print("\n" + "=" * 70)
        if success_count == len(tests):
            print("üéâ TODOS OS TESTES PASSARAM!")
            print("üí° Pipeline ML est√° funcionando perfeitamente!")
            print("\nüìÅ Arquivos gerados:")
            print("   ‚Ä¢ previsoes_energia_solar_30_dias.csv")
            print("   ‚Ä¢ performance_modelos.csv")
            print("   ‚Ä¢ resumo_previsoes_por_usina.csv")
            print("   ‚Ä¢ importancia_features.csv")
        else:
            print(f"‚ö†Ô∏è {success_count}/{len(tests)} testes passaram")
            print("üîß Pipeline precisa de ajustes")
        
        # Fechar conex√µes
        self.pipeline.close_connections()
        
        return success_count == len(tests)

def main():
    """Fun√ß√£o principal"""
    tester = SolarMLTester()
    return tester.run_complete_test()

if __name__ == "__main__":
    main()